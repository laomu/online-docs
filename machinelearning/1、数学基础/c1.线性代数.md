# 机器学习与深度学习中的线性代数学习大纲

## 一、基础概念

1. **标量、向量、矩阵与张量**
   - **标量**：单个数值，如实数或复数。
   - **向量**：一维数组，具有方向和大小。
   - **矩阵**：二维数组，用于表示线性变换。
   - **张量**：多维数组，用于表示高维数据。
2. **维度与形状**
   - 向量的维度（长度）。
   - 矩阵的维度（行数和列数）。
   - 张量的维度（各维度的大小）。

## 二、矩阵的基本运算

1. **加法与减法**
   - 矩阵加法：同维度矩阵逐元素相加。
   - 矩阵减法：同维度矩阵逐元素相减。
2. **标量乘法**
   - 矩阵与标量相乘，每个元素乘以标量。
3. **矩阵乘法**
   - 矩阵 **A**（*m*×*n*）与矩阵 **B**（*n*×*p*）相乘，结果矩阵 **C**（*m*×*p*），其中 *c**ij*=∑*k*=1*n**a**ik**b**kj*。
   - 矩阵乘法的性质：结合律、分配律、非交换性。
4. **转置**
   - 矩阵的转置：行列互换，即 (**A***T*)*ij*=*a**ji*。
   - 转置的性质：(**A***T*)*T*=**A**，(**A**+**B**)*T*=**A***T*+**B***T*，(**AB**)*T*=**B***T***A***T*。

## 三、特殊矩阵

1. **单位矩阵**
   - 主对角线元素为 1，其余元素为 0 的方阵。
   - 单位矩阵的性质：**IA**=**AI**=**A**。
2. **对角矩阵**
   - 主对角线以外的元素全为 0 的矩阵。
   - 对角矩阵的性质：对角矩阵的乘法和逆矩阵的计算较为简单。
3. **对称矩阵**
   - 满足 **A**=**A***T* 的矩阵。
   - 对称矩阵的性质：特征值为实数，特征向量正交。
4. **正交矩阵**
   - 满足 **Q***T***Q**=**Q****Q***T*=**I** 的矩阵。
   - 正交矩阵的性质：行列式为 ±1，逆矩阵等于转置矩阵。

## 四、行列式与逆矩阵

1. **行列式**
   - 定义：行列式是一个标量，用于描述矩阵的缩放因子。
   - 计算方法：对于 2×2 和 3×3 矩阵的行列式计算公式。
   - 行列式的性质：行列式的乘法性质、转置性质、行列变换性质。
2. **逆矩阵**
   - 定义：矩阵 **A** 的逆矩阵 **A**−1 满足 **A****A**−1=**A**−1**A**=**I**。
   - 逆矩阵的计算方法：高斯消元法、伴随矩阵法。
   - 逆矩阵的性质：逆矩阵的唯一性、逆矩阵的转置性质、逆矩阵的乘法性质。

## 五、向量空间与线性变换

1. **向量空间**
   - 定义：向量空间是一组向量的集合，满足加法和标量乘法的封闭性。
   - 子空间：向量空间的一个子集，也是向量空间。
   - 基与维数：基是一组线性无关的向量，维数是基向量的个数。
2. **线性变换**
   - 定义：线性变换是将一个向量空间映射到另一个向量空间的函数，满足加法和标量乘法的保持性。
   - 矩阵表示：线性变换可以用矩阵表示，矩阵的列向量是基向量的像。
   - 特征值与特征向量：矩阵 **A** 的特征值 *λ* 和特征向量 **v** 满足 **Av**=*λ***v**。
   - 特征值与特征向量的计算方法：特征多项式、特征方程。
   - 特征值与特征向量的性质：特征值的代数重数与几何重数、特征向量的正交性。

## 六、矩阵分解

1. **LU 分解**
   - 定义：将矩阵 **A** 分解为一个下三角矩阵 **L** 和一个上三角矩阵 **U** 的乘积，即 **A**=**LU**。
   - LU 分解的计算方法：高斯消元法。
   - LU 分解的应用：解线性方程组、计算行列式。
2. **QR 分解**
   - 定义：将矩阵 **A** 分解为一个正交矩阵 **Q** 和一个上三角矩阵 **R** 的乘积，即 **A**=**QR**。
   - QR 分解的计算方法：格拉姆-施密特正交化过程。
   - QR 分解的应用：最小二乘问题、特征值计算。
3. **奇异值分解（SVD）**
   - 定义：将矩阵 **A** 分解为一个正交矩阵 **U**、一个对角矩阵 **Σ** 和一个正交矩阵 **V***T* 的乘积，即 **A**=**UΣ****V***T*。
   - 奇异值分解的计算方法：幂迭代法、雅可比方法。
   - 奇异值分解的应用：数据降维、图像压缩、推荐系统。

## 七、范数与条件数

1. **范数**
   - 定义：范数是一个非负实数，用于衡量向量或矩阵的大小。
   - 常见范数：
     - 向量范数：*L*1 范数（曼哈顿距离）、*L*2 范数（欧几里得距离）、*L*∞ 范数（无穷范数）。
     - 矩阵范数：Frobenius 范数、谱范数（最大奇异值）。
   - 范数的性质：正定性、齐次性、三角不等式。
2. **条件数**
   - 定义：条件数用于衡量矩阵的病态程度，定义为矩阵的范数与其逆矩阵范数的乘积。
   - 条件数的计算方法：基于矩阵范数的计算。
   - 条件数的意义：条件数越大，矩阵越病态，解线性方程组时误差越大。

## 八、线性方程组的解

1. **齐次线性方程组**
   - 定义：齐次线性方程组的形式为 **Ax**=**0**。
   - 解的性质：齐次线性方程组的解构成一个向量空间，称为零空间。
   - 解的计算方法：高斯消元法。
2. **非齐次线性方程组**
   - 定义：非齐次线性方程组的形式为 **Ax**=**b**。
   - 解的性质：非齐次线性方程组的解可以表示为特解与齐次解的和。
   - 解的计算方法：高斯消元法、最小二乘法。
   - 解的存在性与唯一性：矩阵的秩与解的关系。

## 九、特征值与特征向量

1. **特征值与特征向量的定义**
   - 矩阵 **A** 的特征值 *λ* 和特征向量 **v** 满足 **Av**=*λ***v**。
2. **特征值与特征向量的计算**
   - 特征多项式：det(**A**−*λ***I**)=0。
   - 特征方程的求解方法：代数方法、数值方法。
3. **特征值与特征向量的性质**
   - 特征值的代数重数与几何重数。
   - 特征向量的正交性：对称矩阵的特征向量正交。
4. **特征值分解（谱分解）**
   - 对称矩阵的特征值分解：**A**=**QΛ****Q***T*，其中 **Q** 是正交矩阵，**Λ** 是对角矩阵。
   - 特征值分解的应用：主成分分析（PCA）、图像处理。

## 十、应用

1. **主成分分析（PCA）**
   - 定义：PCA 是一种降维技术，通过特征值分解将数据投影到主成分方向上。
   - PCA 的步骤：数据标准化、计算协方差矩阵、特征值分解、选择主成分、投影数据。
2. **奇异值分解（SVD）**
   - SVD 的应用：数据降维、图像压缩、推荐系统。
3. **最小二乘法**
   - 最小二乘法的定义：最小化误差平方和的方法。
   - 最小二乘法的计算方法：正规方程、QR 分解、SVD 分解。
   - 最小二乘法的应用：线性回归、曲线拟合。